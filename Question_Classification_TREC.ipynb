{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b80777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTS DONE\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# GPU and CPU Check Code\n",
    "# KEEP AT THE TOP\n",
    "############################\n",
    "\n",
    "# !pip install psutil\n",
    "# !pip install gputil\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import spacy\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import multiprocessing\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "print(\"IMPORTS DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773685b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of physical CPUs: 128\n",
      "Number of logical CPUs: 128\n",
      "Number of GPUs: 2\n",
      "GPU 1: NVIDIA A100 80GB PCIe\n",
      "\tUUID: GPU-c9f222a4-cdf9-a690-b27c-fd6ca8dd8832\n",
      "\tMemory Total: 81920.0 MB\n",
      "\tMemory Used: 7.0 MB\n",
      "\tMemory Free: 81042.0 MB\n",
      "\tGPU Utilization: 0.0%\n",
      "\tGPU Temperature: 31.0 °C\n",
      "GPU 2: NVIDIA A100 80GB PCIe\n",
      "\tUUID: GPU-051052d6-9db8-7e01-b26b-69a92eab9f9e\n",
      "\tMemory Total: 81920.0 MB\n",
      "\tMemory Used: 7.0 MB\n",
      "\tMemory Free: 81042.0 MB\n",
      "\tGPU Utilization: 0.0%\n",
      "\tGPU Temperature: 27.0 °C\n"
     ]
    }
   ],
   "source": [
    "# Get the number of CPUs\n",
    "num_cpus = psutil.cpu_count(logical=False)  # physical cores\n",
    "num_logical_cpus = psutil.cpu_count(logical=True)  # logical cores\n",
    "\n",
    "print(f\"Number of physical CPUs: {num_cpus}\")\n",
    "print(f\"Number of logical CPUs: {num_logical_cpus}\")\n",
    "\n",
    "try:\n",
    "    import GPUtil\n",
    "\n",
    "    # Get the number of available GPUs\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    num_gpus = len(gpus)\n",
    "\n",
    "    print(f\"Number of GPUs: {num_gpus}\")\n",
    "\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"GPU {i + 1}: {gpu.name}\")\n",
    "        print(f\"\\tUUID: {gpu.uuid}\")\n",
    "        print(f\"\\tMemory Total: {gpu.memoryTotal} MB\")\n",
    "        print(f\"\\tMemory Used: {gpu.memoryUsed} MB\")\n",
    "        print(f\"\\tMemory Free: {gpu.memoryFree} MB\")\n",
    "        print(f\"\\tGPU Utilization: {gpu.load * 100}%\")\n",
    "        print(f\"\\tGPU Temperature: {gpu.temperature} °C\")\n",
    "except ImportError:\n",
    "    print(\"GPUtil library not found. Cannot check GPU information.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da2b2e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset trec (/home/vmenon19/.cache/huggingface/datasets/trec/default/2.0.0/f2469cab1b5fceec7249fda55360dfdbd92a7a5b545e91ea0f78ad108ffac1c2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03da6004d1584e62979727cb94e1cbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "import spacy\n",
    "\n",
    "# Load spaCy's English model for sentence segmentation\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function for sentence segmentation using spaCy\n",
    "def segment_sentences(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "# Load dataset from Hugging Face datasets library\n",
    "dataset = load_dataset(\"trec\")\n",
    "\n",
    "# Extract train and test splits\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']\n",
    "\n",
    "# Use 'text' and 'coarse_label' as question and label\n",
    "train_texts = train_data['text']\n",
    "train_labels = train_data['coarse_label']\n",
    "\n",
    "test_texts = test_data['text']\n",
    "test_labels = test_data['coarse_label']\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def process_data(texts, labels, max_seq_length=512, max_head_tokens=128, max_tail_tokens=382):\n",
    "    formatted_data = []\n",
    "\n",
    "    for text, label in zip(texts, labels):\n",
    "        # Segment sentences using spaCy\n",
    "        sentences = segment_sentences(text)\n",
    "        processed_text = \" \".join(sentences)\n",
    "\n",
    "        # Tokenize the processed text using BERT tokenizer\n",
    "        tokens = tokenizer.tokenize(processed_text)\n",
    "        # Add [CLS] and [SEP] tokens\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "\n",
    "        if len(tokens) > max_seq_length:\n",
    "            # Keep the first max_head_tokens and the last max_tail_tokens\n",
    "            head_tokens = tokens[1:max_head_tokens + 1]\n",
    "            tail_tokens = tokens[-max_tail_tokens:]\n",
    "            tokens = head_tokens + tail_tokens\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Padding\n",
    "        padding_length = max_seq_length - len(input_ids)\n",
    "        input_ids += [tokenizer.pad_token_id] * padding_length\n",
    "        attention_mask += [0] * padding_length\n",
    "\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "        # Append to formatted data including 'label'\n",
    "        formatted_data.append({\n",
    "            'input_ids': input_ids.unsqueeze(0),  # Unsqueeze for batch dimension\n",
    "            'attention_mask': attention_mask.unsqueeze(0),  # Unsqueeze for batch dimension\n",
    "            'label': label\n",
    "        })\n",
    "\n",
    "    return formatted_data\n",
    "\n",
    "# Process train and test data\n",
    "formatted_train_data = process_data(train_texts, train_labels)\n",
    "formatted_test_data = process_data(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82aa6cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 - Average Training Loss: 0.7852532966225817\n",
      "Validation Loss: 0.2061, Validation Accuracy: 0.9476\n",
      "Epoch 2/4 - Average Training Loss: 0.17913801402768545\n",
      "Validation Loss: 0.1140, Validation Accuracy: 0.9639\n",
      "Epoch 3/4 - Average Training Loss: 0.08909102892421447\n",
      "Validation Loss: 0.1174, Validation Accuracy: 0.9694\n",
      "Epoch 4/4 - Average Training Loss: 0.054852647482205114\n",
      "Validation Loss: 0.1197, Validation Accuracy: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.9720\n"
     ]
    }
   ],
   "source": [
    "# Convert data to PyTorch DataLoader\n",
    "batch_size = 24\n",
    "\n",
    "train_inputs = torch.cat([data['input_ids'] for data in formatted_train_data])\n",
    "train_masks = torch.cat([data['attention_mask'] for data in formatted_train_data])\n",
    "train_labels = torch.tensor([data['label'] for data in formatted_train_data])\n",
    "\n",
    "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_inputs = torch.cat([data['input_ids'] for data in formatted_test_data])\n",
    "test_masks = torch.cat([data['attention_mask'] for data in formatted_test_data])\n",
    "test_labels = torch.tensor([data['label'] for data in formatted_test_data])\n",
    "\n",
    "test_dataset = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define BERT model for sequence classification\n",
    "class BERTSequenceClassifier(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BERTSequenceClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Initialize the BERT-based sequence classifier model\n",
    "coarse_labels = dataset['train']['coarse_label']\n",
    "num_labels = len(set(coarse_labels))\n",
    "\n",
    "model = BERTSequenceClassifier(num_labels=num_labels)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the criterion (loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, betas=(0.9, 0.999))\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1 * len(train_dataloader),\n",
    "                                            num_training_steps=len(train_dataloader) * 4)\n",
    "\n",
    "# Training loop\n",
    "best_val_accuracy = 0.0\n",
    "best_model_path = \"best_model.pt\"\n",
    "\n",
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, masks, labels = [tensor.to(device) for tensor in batch]\n",
    "        outputs = model(inputs, attention_mask=masks)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Average Training Loss: {avg_train_loss}\")\n",
    "\n",
    "    # Evaluation on validation set\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    total_eval_accuracy = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            inputs, masks, labels = [tensor.to(device) for tensor in batch]\n",
    "            outputs = model(inputs, attention_mask=masks)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            logits = outputs.detach().cpu().numpy()\n",
    "            label_ids = labels.to('cpu').numpy()\n",
    "            total_eval_accuracy += (logits.argmax(axis=1) == label_ids).mean()\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(test_dataloader)\n",
    "    avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.4f}\")\n",
    "\n",
    "    # Save the best model based on validation accuracy\n",
    "    if avg_val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = avg_val_accuracy\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "# Load the best model for testing\n",
    "best_model = BERTSequenceClassifier(num_labels=num_labels)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "best_model.to(device)\n",
    "\n",
    "# Evaluation on the test set using the best model\n",
    "best_model.eval()\n",
    "total_test_accuracy = 0\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        inputs, masks, labels = [tensor.to(device) for tensor in batch]\n",
    "        outputs = best_model(inputs, attention_mask=masks)\n",
    "\n",
    "        logits = outputs.detach().cpu().numpy()\n",
    "        label_ids = labels.to('cpu').numpy()\n",
    "        total_test_accuracy += (logits.argmax(axis=1) == label_ids).sum()\n",
    "\n",
    "final_test_accuracy = total_test_accuracy / len(test_dataset)\n",
    "print(f\"Final Test Accuracy: {final_test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:nlp2023v2]",
   "language": "python",
   "name": "conda-env-nlp2023v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
